{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "3AVFk89sVMJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers peft torch accelerate bitsandbytes\n"
      ],
      "metadata": {
        "id": "hN6jFqa-VOXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL_ThbvPaMqM",
        "outputId": "fcbcef48-6507-4fc4-cb5e-e23f5c242d21"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Google drive folder with trained model data**"
      ],
      "metadata": {
        "id": "9ZR5KIMwVmfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thOPlSm3BVuN",
        "outputId": "e3b6b9d3-88f4-433a-a1ce-69f89e4fb2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading your trained model files from Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1ufkk-Pok1Jj27YxjWSmD92pXrC5DKv1q adapter_config.json\n",
            "Processing file 1TyESkqVSppq_w1MROrBxQvXghQSNtWJ1 adapter_model.safetensors\n",
            "Processing file 1Tdxku1odefxYlIzr_NBf0IImK26iSV_C sample_training_data.json\n",
            "Processing file 1CxtjWrFArCUY2-Jnn_QinsX_tOYoPyAD special_tokens_map.json\n",
            "Processing file 1SEt3zkMfSpB969JwEbJhTmefGRNp5Iij tokenizer_config.json\n",
            "Processing file 16l-plbzWhdXhJSPB1eSvnD7YS-vsSkrZ tokenizer.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ufkk-Pok1Jj27YxjWSmD92pXrC5DKv1q\n",
            "To: /content/model_files/model_files/QA_finetuning_test/adapter_config.json\n",
            "100%|██████████| 765/765 [00:00<00:00, 2.98MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TyESkqVSppq_w1MROrBxQvXghQSNtWJ1\n",
            "From (redirected): https://drive.google.com/uc?id=1TyESkqVSppq_w1MROrBxQvXghQSNtWJ1&confirm=t&uuid=2fd11ce8-1410-47f6-bf9c-4fc3ed9700ad\n",
            "To: /content/model_files/model_files/QA_finetuning_test/adapter_model.safetensors\n",
            "100%|██████████| 446M/446M [00:08<00:00, 54.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Tdxku1odefxYlIzr_NBf0IImK26iSV_C\n",
            "To: /content/model_files/model_files/QA_finetuning_test/sample_training_data.json\n",
            "100%|██████████| 20.9k/20.9k [00:00<00:00, 32.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CxtjWrFArCUY2-Jnn_QinsX_tOYoPyAD\n",
            "To: /content/model_files/model_files/QA_finetuning_test/special_tokens_map.json\n",
            "100%|██████████| 463/463 [00:00<00:00, 1.54MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SEt3zkMfSpB969JwEbJhTmefGRNp5Iij\n",
            "To: /content/model_files/model_files/QA_finetuning_test/tokenizer_config.json\n",
            "100%|██████████| 19.0k/19.0k [00:00<00:00, 28.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16l-plbzWhdXhJSPB1eSvnD7YS-vsSkrZ\n",
            "To: /content/model_files/model_files/QA_finetuning_test/tokenizer.json\n",
            "100%|██████████| 7.15M/7.15M [00:00<00:00, 30.6MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/model_files/model_files/QA_finetuning_test/adapter_config.json',\n",
              " '/content/model_files/model_files/QA_finetuning_test/adapter_model.safetensors',\n",
              " '/content/model_files/model_files/QA_finetuning_test/sample_training_data.json',\n",
              " '/content/model_files/model_files/QA_finetuning_test/special_tokens_map.json',\n",
              " '/content/model_files/model_files/QA_finetuning_test/tokenizer_config.json',\n",
              " '/content/model_files/model_files/QA_finetuning_test/tokenizer.json']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "os.makedirs(\"model_files\", exist_ok=True)\n",
        "os.chdir(\"model_files\")\n",
        "\n",
        "print(\"Downloading your trained model files from Google Drive...\")\n",
        "\n",
        "folder_url = \"https://drive.google.com/drive/folders/1AKzzA2WObNmontbDVaAY8ZPNF7g669Mr\"\n",
        "\n",
        "gdown.download_folder(folder_url, quiet=False, use_cookies=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check downloaded files**"
      ],
      "metadata": {
        "id": "vxUKTc6KVv6a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9yJjzi9GQaP",
        "outputId": "47dd9204-4650-4067-ba76-7752adbdc609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloaded files:\n",
            "  ./QA_finetuning_test/adapter_model.safetensors: 425.0 MB\n",
            "  ./QA_finetuning_test/special_tokens_map.json: 0.0 MB\n",
            "  ./QA_finetuning_test/sample_training_data.json: 0.0 MB\n",
            "  ./QA_finetuning_test/adapter_config.json: 0.0 MB\n",
            "  ./QA_finetuning_test/tokenizer.json: 6.8 MB\n",
            "  ./QA_finetuning_test/tokenizer_config.json: 0.0 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDownloaded files:\")\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        size = os.path.getsize(filepath) / (1024*1024)  # Size in MB\n",
        "        print(f\"  {filepath}: {size:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change runtime type if needed** \\\\\n",
        "Loading the model will need higher RAM"
      ],
      "metadata": {
        "id": "0OzWR8xMV0OP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIwzJWytBV6-",
        "outputId": "fb7fd25d-2987-4d86-9d46-a16b8347bafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load trained Phi4 model** \\\\\n",
        "trained on 34 files from Bohan's SOS dataset"
      ],
      "metadata": {
        "id": "zB67rxQdWA4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test with sample conversations from dataset** \\\\\n",
        "Resulting metric is a success rate of the answers \\\\\n",
        "Results saved to `adapter_test_results.json`"
      ],
      "metadata": {
        "id": "Lfd1QpL7Wf9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "29FtTSyM7x9e",
        "outputId": "a43a7aeb-99b9-46c4-d743-0158c7e82cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading questions from ./QA_finetuning_test/sample_training_data.json...\n",
            "Found 5 conversations in sample data\n",
            " Extracted 5 questions from sample training data\n",
            "\n",
            " Testing model with 5 questions...\n",
            "================================================================================\n",
            "\n",
            " QUESTION 1:\n",
            "Consider the following constraints:\n",
            "g_1 = (z - 2) >= 0\n",
            "g_2 = (y + 2*z - 3) >= 0\n",
            "g_3 = (2*y + z) >= 0\n",
            "g_4 = (y^2*z^2 - 2*y*z - 2) >= 0\n",
            "g_5 = (z + 2) >=...\n",
            "\n",
            " GENERATING ANSWER...\n",
            "GENERATED: y*z^3 + 6*y*z^2 + 12*y*z + 8*y + 3*y + 2*z^4 + 9*z^3 + 6*z^2 - 20*z + 6*z - 24 - 9\n",
            " ORIGINAL:  y*z^3 + 6*y*z^2 + 12*y*z + 8*y + 3*y + 2*z^4 + 9*z^3 + 6*z^2 - 20*z + 6*z - 24 - 9...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " QUESTION 2:\n",
            "Consider the following constraints:\n",
            "g_1 = (x*z + 2) >= 0\n",
            "g_2 = (z + 1) >= 0\n",
            "g_3 = (z*(x - 3)) >= 0\n",
            "\n",
            "Consider the target polynomial:\n",
            "f = 8*x^6*z^3 + 8*...\n",
            "\n",
            " GENERATING ANSWER...\n",
            "GENERATED: 8*x^6*z^3 + 8*x^6*z^2 - 8*x^5*z^4 - 8*x^5*z^3 - 48*x^5*z^2 - 48*x^5*z + 2*x^4*z^5 + 2*x^4*z^4 + 48*x^4*z^3 + 48*x^4*z^2 + 72*x^4*z + 72*x^4 + 5*x^3*z^8 + 25*x^3*z^7 + 40*x^3*z^6 + 20*x^3*z^5 - 12*x^3*z^4 - 12*x^3\n",
            " ORIGINAL:  8*x^6*z^3 + 8*x^6*z^2 - 8*x^5*z^4 - 8*x^5*z^3 - 48*x^5*z^2 - 48*x^5*z + 2*x^4*z^5 + 2*x^4*z^4 + 48*x^4*z^3 + 48*x^4*z^2 + 72*x^4*z + 72*x^4 + 5*x^3*z^...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " QUESTION 3:\n",
            "Consider the following constraints:\n",
            "g_1 = (3*x^2 + 2*x + 2) >= 0\n",
            "g_2 = (4*z^2) >= 0\n",
            "g_3 = (x^2*z + x - 2) >= 0\n",
            "\n",
            "Consider the target polynomial:\n",
            "f = 2*...\n",
            "\n",
            " GENERATING ANSWER...\n",
            "GENERATED: 2*x^4*z^2 + 4*x^3*z - 8*x^2*z + 2*x^2 - 8*x + 8\n",
            " ORIGINAL:  2*x^4*z^2 + 4*x^3*z - 8*x^2*z + 2*x^2 - 8*x + 8...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " QUESTION 4:\n",
            "Consider the following constraints:\n",
            "\n",
            "\n",
            "Consider the target polynomial:\n",
            "f = 3*y^12 - 6*y^10 - 3*y^8 + 12*y^6 + 2*y^4 + 8*y^3 + 4\n",
            "\n",
            "Our objective is to re...\n",
            "\n",
            " GENERATING ANSWER...\n",
            "GENERATED: 3*y^12 - 6*y^10 - 3*y^8 + 12*y^6 + 2*y^4 + 8*y^3 + 4\n",
            " ORIGINAL:  3*y^12 - 6*y^10 - 3*y^8 + 12*y^6 + y^4 + 4*y^4 - 3*y^4 + 8*y^3 + 2*y^2 + 4*y^2 - 6*y^2 + 1 + 3...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " QUESTION 5:\n",
            "Consider the following constraints:\n",
            "g_1 = ((x + 3)^2) >= 0\n",
            "g_2 = (1 - 2*x) >= 0\n",
            "\n",
            "Consider the target polynomial:\n",
            "f = 5 - 10*x\n",
            "\n",
            "Our objective is to rew...\n",
            "\n",
            " GENERATING ANSWER...\n",
            "GENERATED: -10*x + 5\n",
            " ORIGINAL:  -10*x + 5...\n",
            "--------------------------------------------------------------------------------\n",
            "Success rate: 5/5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fdf9be47-73c0-4881-9049-95e2cb9f43d8\", \"adapter_test_results.json\", 5888)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "def load_questions_from_sample_data():\n",
        "    sample_file = \"./QA_finetuning_test/sample_training_data.json\"\n",
        "\n",
        "    print(f\" Loading questions from {sample_file}...\")\n",
        "\n",
        "    with open(sample_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"Found {len(data)} conversations in sample data\")\n",
        "\n",
        "    questions = []\n",
        "\n",
        "    for i, conversation in enumerate(data):\n",
        "        messages = conversation['messages']\n",
        "\n",
        "        for j, message in enumerate(messages):\n",
        "            if (message['role'] == 'user' and\n",
        "                len(message['content']) > 100 and\n",
        "                'Consider the following constraints' in message['content']):\n",
        "\n",
        "                original_answer = None\n",
        "                if j + 1 < len(messages) and messages[j + 1]['role'] == 'assistant':\n",
        "                    original_answer = messages[j + 1]['content']\n",
        "\n",
        "                questions.append({\n",
        "                    'conversation_id': i,\n",
        "                    'question': message['content'],\n",
        "                    'original_answer': original_answer\n",
        "                })\n",
        "                break\n",
        "\n",
        "    print(f\" Extracted {len(questions)} questions from sample training data\")\n",
        "    return questions\n",
        "\n",
        "if 'model_loaded' not in globals():\n",
        "    model_loaded = False\n",
        "    print(\"model_loaded variable not found, assuming model is not loaded.\")\n",
        "\n",
        "if model_loaded:\n",
        "    try:\n",
        "        test_questions = load_questions_from_sample_data()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading questions: {e}\")\n",
        "        test_questions = []\n",
        "else:\n",
        "    print(\"Model not loaded, skipping loading test questions.\")\n",
        "    test_questions = []\n",
        "\n",
        "\n",
        "def generate_answer(model, tokenizer, question):\n",
        "    prompt = f\"\"\"<|im_start|>system\n",
        "You are an expert in symbolic computation and polynomial decomposition.\n",
        "Your task is to help rewrite a target polynomial into the required form based on given inequality premises.\n",
        "<|im_end|>\n",
        "<|im_start|>user\n",
        "{question}\n",
        "<|im_end|>\n",
        "<|im_start|>assistant\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=150,\n",
        "            temperature=0.3,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id, # Added pad_token_id\n",
        "            eos_token_id=tokenizer.eos_token_id, # Added eos_token_id\n",
        "            repetition_penalty=1.1 # Added repetition_penalty\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "    if \"<|im_start|>assistant\" in response:\n",
        "        answer = response.split(\"<|im_start|>assistant\")[-1].strip()\n",
        "    else:\n",
        "        answer = response.strip()\n",
        "\n",
        "    if answer.endswith(\"<|im_end|>\"):\n",
        "        answer = answer[:-len(\"<|im_end|>\")].strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "if not model_loaded:\n",
        "    print(\"Cannot run tests - model failed to load\")\n",
        "else:\n",
        "    results = []\n",
        "\n",
        "    num_tests = min(10, len(test_questions))\n",
        "    test_subset = test_questions[:num_tests]\n",
        "\n",
        "    print(f\"\\n Testing model with {num_tests} questions...\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for i, q_data in enumerate(test_subset, 1):\n",
        "        question = q_data['question']\n",
        "        original_answer = q_data['original_answer']\n",
        "\n",
        "        print(f\"\\n QUESTION {i}:\")\n",
        "        print(f\"{question[:150]}...\")\n",
        "\n",
        "        print(f\"\\n GENERATING ANSWER...\")\n",
        "\n",
        "        try:\n",
        "            generated_answer = generate_answer(model, tokenizer, question)\n",
        "\n",
        "            print(f\"GENERATED: {generated_answer}\")\n",
        "            print(f\" ORIGINAL:  {original_answer[:150]}...\" if original_answer else \"N/A\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            results.append({\n",
        "                \"question_id\": i,\n",
        "                \"question\": question,\n",
        "                \"generated_answer\": generated_answer,\n",
        "                \"original_answer\": original_answer,\n",
        "                \"status\": \"success\"\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Generation error: {str(e)}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            results.append({\n",
        "                \"question_id\": i,\n",
        "                \"question\": question,\n",
        "                \"generated_answer\": f\"Error: {str(e)}\",\n",
        "                \"original_answer\": original_answer,\n",
        "                \"status\": \"error\"\n",
        "            })\n",
        "\n",
        "    if results:\n",
        "        with open('/content/adapter_test_results.json', 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        successful_results = [r for r in results if r['status'] == 'success']\n",
        "        print(f\"Success rate: {len(successful_results)}/{len(results)}\")\n",
        "\n",
        "        from google.colab import files\n",
        "        try:\n",
        "            files.download('/content/adapter_test_results.json')\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading file: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}